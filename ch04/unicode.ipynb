{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=5)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    ">>> s1 = 'café'\n",
    ">>> s2 = 'cafe\\\\u0301'\n",
    ">>> s1, s2\n",
    "('café', 'café')\n",
    ">>> len(s1), len(s2)\n",
    "(4, 5)\n",
    ">>> s1 == s2\n",
    "False\n",
    "\"\"\"\n",
    "\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=7)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "\"\"\"\n",
    "\n",
    ">>> s1 = 'café'\n",
    ">>> s2 = 'cafe\\\\u0301'\n",
    ">>> len(s1), len(s2)\n",
    "(4, 5)\n",
    ">>> len(normalize('NFC', s1)), len(normalize('NFC', s2))\n",
    "(4, 4)\n",
    ">>> len(normalize('NFD', s1)), len(normalize('NFD', s2))\n",
    "(5, 5)\n",
    ">>> normalize('NFC', s1) == normalize('NFC', s2)\n",
    "True\n",
    ">>> normalize('NFD', s1) == normalize('NFD', s2)\n",
    "True\n",
    "\"\"\"\n",
    "\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=6)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "\n",
    "\"\"\"\n",
    "\n",
    ">>> ohm = '\\\\u2126'\n",
    ">>> name(ohm)\n",
    "'OHM SIGN'\n",
    ">>> ohm_c = normalize('NFC', ohm)\n",
    ">>> name(ohm_c)\n",
    "'GREEK CAPITAL LETTER OMEGA'\n",
    ">>> ohm == ohm_c\n",
    "False\n",
    ">>> normalize('NFC', ohm) == normalize('NFC', ohm_c)\n",
    "True\n",
    "\"\"\"\n",
    "\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=9)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "\n",
    "\"\"\"\n",
    "\n",
    ">>> half = '½'\n",
    ">>> normalize('NFKC', half)\n",
    "'1⁄2'\n",
    ">>> four_squared = '4²'\n",
    ">>> normalize('NFKC', four_squared)\n",
    "'42'\n",
    ">>> micro = 'µ'\n",
    ">>> micro_kc = normalize('NFKC', micro)\n",
    ">>> micro, micro_kc\n",
    "('µ', 'μ')\n",
    ">>> ord(micro), ord(micro_kc)\n",
    "(181, 956)\n",
    ">>> name(micro), name(micro_kc)\n",
    "('MICRO SIGN', 'GREEK SMALL LETTER MU')\n",
    "\"\"\"\n",
    "\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=9)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from unicodedata import name\n",
    "\n",
    "\"\"\"\n",
    "\n",
    ">>> micro = 'µ'\n",
    ">>> name(micro)\n",
    "'MICRO SIGN'\n",
    ">>> micro_cf = micro.casefold()\n",
    ">>> name(micro_cf)\n",
    "'GREEK SMALL LETTER MU'\n",
    ">>> micro, micro_cf\n",
    "('µ', 'μ')\n",
    ">>> eszett = 'ß'\n",
    ">>> name(eszett)\n",
    "'LATIN SMALL LETTER SHARP S'\n",
    ">>> eszett_cf = eszett.casefold()\n",
    ">>> eszett, eszett_cf\n",
    "('ß', 'ss')\n",
    "\"\"\"\n",
    "\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=12)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "\n",
    "def nfc_equal(s1, s2):\n",
    "    return normalize('NFC', s1) == normalize('NFC', s2)\n",
    "\n",
    "\n",
    "def fold_equal(s1, s2):\n",
    "    return normalize('NFC', s1).casefold() \\\n",
    "        == normalize('NFC', s2).casefold()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    ">>> s1 = 'café'\n",
    ">>> s2 = 'cafe\\\\u0301'\n",
    ">>> s1 == s2\n",
    "False\n",
    ">>> nfc_equal(s1, s2)\n",
    "True\n",
    ">>> nfc_equal('A', 'a')\n",
    "False\n",
    "\n",
    ">>> s3 = 'Straße'\n",
    ">>> s4 = 'strasse'\n",
    ">>> s3 == s4\n",
    "False\n",
    ">>> nfc_equal(s3, s4)\n",
    "False\n",
    ">>> fold_equal(s3, s4)\n",
    "True\n",
    ">>> fold_equal(s1, s2)\n",
    "True\n",
    ">>> fold_equal('A', 'a')\n",
    "True\n",
    "\"\"\"\n",
    "\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=7)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "single_map = str.maketrans(\"\"\"‚ƒ„†ˆ‹‘’“”•–—˜›\"\"\",\n",
    "                           \"\"\"'f\"*^<''\"\"---~>\"\"\")\n",
    "\n",
    "multi_map = str.maketrans({\n",
    "    '€': '<euro>',\n",
    "    '…': '...',\n",
    "    'Œ': 'OE',\n",
    "    '™': '(TM)',\n",
    "    'œ': 'oe',\n",
    "    '‰': '<per mille>',\n",
    "    '‡': '**',\n",
    "})\n",
    "\n",
    "multi_map.update(single_map)\n",
    "\n",
    "\n",
    "def shave_marks(txt):\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c))\n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "\n",
    "\n",
    "def shave_marks_latin(txt):\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    latin_base = False\n",
    "    keepers = []\n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base:\n",
    "            continue\n",
    "\n",
    "        keepers.append(c)\n",
    "        if not unicodedata.combining(c):\n",
    "            latin_base = c in string.ascii_letters\n",
    "\n",
    "    shaved = ''.join(keepers)\n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "\n",
    "\n",
    "def dewinize(txt):\n",
    "    return txt.translate(multi_map)\n",
    "\n",
    "\n",
    "def asciize(txt):\n",
    "    no_marks = shave_marks_latin(dewinize(txt))\n",
    "    no_marks = no_marks.replace('ß', 'ss')\n",
    "    return unicodedata.normalize('NFKC', no_marks)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    ">>> order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    ">>> shave_marks(order)\n",
    "'“Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”'\n",
    ">>> shave_marks_latin(order)\n",
    "'“Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”'\n",
    ">>> dewinize(order)\n",
    "'\"Herr Voß: - ½ cup of OEtker(TM) caffè latte - bowl of açaí.\"'\n",
    ">>> asciize(order)\n",
    "'\"Herr Voss: - 1⁄2 cup of OEtker(TM) caffe latte - bowl of acai.\"'\n",
    "\n",
    ">>> greek = 'Ζέφυρος, Zéfiro'\n",
    ">>> shave_marks(greek)\n",
    "'Ζεφυρος, Zefiro'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}